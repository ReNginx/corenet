{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import math\n",
    "import k3d\n",
    "import os.path\n",
    "import torch as t\n",
    "import dataclasses\n",
    "\n",
    "if \"./src\" not in sys.path:\n",
    "    sys.path.append(\"./src\")\n",
    "from corenet.data import batched_example\n",
    "from corenet import tf_model as tf_model_lib\n",
    "from corenet import super_resolution as super_resolution_lib\n",
    "from corenet.geometry import transformations as transformations_lib\n",
    "\n",
    "color_palette = [\n",
    "    0x00ffff, 0xffff00, 0xff00ff, 0x00ff80, 0xff0000, 0x0000ff, 0x80ff00, 0x0080ff, 0x8000ff, 0xff8000, \n",
    "    0x00ff00, 0xff0080, 0xffff80, 0x80ffff, 0xff80ff, 0x80ff80, 0x8080ff, 0xff8080 ]\n",
    "\n",
    "def plot_result(src_image, grid, u=1):\n",
    "    c, d, h, w = grid.shape\n",
    "    plot = k3d.plot()\n",
    "    obj_idx = 0\n",
    "    for obj_grid in grid:\n",
    "        if u > 1:\n",
    "            kernel = grid.new_ones([1, 1, u, u, u], dtype=t.float32) / u**3\n",
    "            obj_grid = t.nn.functional.pad(obj_grid[None, None], [u//2, u//2-1, u//2, u//2-1, u//2, u//2-1])\n",
    "            obj_grid = t.conv3d(obj_grid, kernel)[0, 0]\n",
    "        if obj_grid.max() <= 0.5:\n",
    "            continue\n",
    "        obj_grid = t.nn.functional.pad(obj_grid, [1, 1, 1, 1, 1, 1]).cpu().numpy()\n",
    "        vertices, faces, _, _ = measure.marching_cubes(obj_grid, level=0.5)\n",
    "        vertices = (vertices - 1) / (w, h, d)\n",
    "        zz, yy, xx = [vertices[..., i] for i in range(3)]\n",
    "        vertices = np.stack([xx, zz, yy], -1) - 0.5\n",
    "        faces = np.flip(faces, [-1])\n",
    "        plot += k3d.mesh(vertices.astype(np.float32), faces.astype(np.uint32), color=color_palette[obj_idx])\n",
    "        obj_idx += 1\n",
    "    PIL.Image.fromarray(example_image.numpy()).save(buf := io.BytesIO(), format=\"png\")\n",
    "    s=2.1\n",
    "    plot += k3d.texture(\n",
    "        binary=buf.getvalue(),file_format=\"png\",\n",
    "        model_matrix=[[s, 0, 0, 0], [0, 0, 1, 0.5], [0, -s, 0, 0], [0, 0, 0, 1.0]])\n",
    "    plot += k3d.texture(binary=buf.getvalue(),file_format=\"png\",\n",
    "                        model_matrix=[[0.5, 0, 0, -1.5], [0, 0, 1, 0.5], [0, -0.5, 0, 0], [0, 0, 0, 1.0]])\n",
    "    plot.camera = [0, -1.3666666, 0, 0, 0, 0, 0, 0, 1]\n",
    "    plot.camera_auto_fit = False\n",
    "    plot.grid_visible = False\n",
    "    plot.camera_mode = \"orbit\"\n",
    "\n",
    "    return plot\n",
    "   \n",
    "pretrained_models = {\n",
    "    \"m7\": \"example_pair_m7_bd2d7cd9ebcc03f0691ac421b36085911c29f420d288bdf3d8533dcfe74a414f.webp\",\n",
    "    \"h5\": \"example_single_h5_a7862633361da9b8cb9e2ad0cb23c7b490c324686e185a53045910819a07f824.webp\",\n",
    "    \"h7\": \"example_single_h7_a7862633361da9b8cb9e2ad0cb23c7b490c324686e185a53045910819a07f824.webp\",\n",
    "    \"y1\": \"example_single_y1_6976ae6754872044ce00af95aafeb09fae4b733983da5fa25377fd5b9cf7dee8.webp\",\n",
    "    \"m9\": \"example_triplet_m9_efe6cd70d5f1a2636c39834fcff598d1fa4525f8d73b115d5eb2f2210527f047.webp\",\n",
    "}\n",
    "\n",
    "camera_transform = t.as_tensor([[\n",
    "    [ 1.7320507 ,  0.        ,  0.        , -0.8660253 ],\n",
    "    [ 0.        , -1.7320507 ,  0.        ,  0.8660253 ],\n",
    "    [ 0.        ,  0.        ,  1.00002   ,  0.8664839 ],\n",
    "    [ 0.        ,  0.        ,  1.        ,  0.86666656]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(tf_model_lib)\n",
    "importlib.reload(super_resolution_lib)\n",
    "\n",
    "model_name = \"h7\"  # The model to show, must be one of the keys of `pretrained_models`\n",
    "data_dir = \"data/paper_tf_models\"  # Root directory containing the model and the example image\n",
    "output_resolution = (128,)*3\n",
    "# output_resolution = (32,)*3  # Uncomment to display at native resolution for model y1\n",
    "\n",
    "example_image = PIL.Image.open(os.path.join(data_dir, pretrained_models[model_name]))\n",
    "example_image = t.as_tensor(np.array(example_image))\n",
    "\n",
    "inference_fn = tf_model_lib.super_resolution_from_tf_model(os.path.join(data_dir, model_name + \".pb\"))\n",
    "input_image=example_image.permute([2, 0, 1])[None].cuda()\n",
    "camera_transform=camera_transform.cuda()\n",
    "w2x_transform=transformations_lib.scale(output_resolution)[None].cuda()\n",
    "grid_sampling_offset = t.ones([1, 3], device=\"cuda\") * 0.5\n",
    "grid_pmf = inference_fn(\n",
    "    input_image, camera_transform, w2x_transform, grid_sampling_offset, output_resolution)[0, 1:]\n",
    "plot_result(example_image, grid_pmf, inference_fn.get_resolution_multiplier(output_resolution))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
